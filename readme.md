# VRC(Voice Realtime Conversion)

## 概要

話者Aの声質を話者Bの声質にCycleGANを用いて変換するプログラムです。

1. 10分ぐらい録音して、44100Hz,16bit,モノラル,非圧縮で保存
2. 自分の声を"./dataset/train/A"に配置
3. 相手の声を"./dataset/train/B"に配置

``` bash
 python train.py
```

GTX1070なら1時間半ぐらいで完了します。

## インストール（環境構築）

以下のライブラリをインストールしてください。

### 変換時

- chainer(cupyやchainerX等のGPU関係を利用すること推奨)
- numpy
- pyworld
- pyaudio(変換時のみ)
- matplotlib(学習時のみ)

## 学習の手順

"setting.json"ファイルで学習の設定が行なえます。
主に出力先の設定を記述します。
以下の手順で音声ファイルを用意します。

"dataset"ディレクトリを用意して、以下に"train","test","patch"を用意してください。

**16000Hz,int16,モノラル,非圧縮音声ファイル**を"dataset/train/A/"と"dataset/train/B/"に話者ごとに分けて入れてください。
なお、**同じ文章を読まなくても構いません**。ただし、データが偏った場合は正常に学習できない場合があります。

なお、学習を正常に収束させるためには5分以上の録音をお勧めします。
(台本.txtを推奨します。読みなれている場合でもおよそ5分ほどかかります。)
なお、前処理としての無音区間の削除は必要ありませんが、無音区間が長時間存在する場合の収束が保証されているわけではありません。

同条件で10秒程度のテスト用ファイル(話者A)を用意して、
"test.wav"を"dataset/test"ディレクトリ以下に保存してください。

``` bash
 |
 |_dataset___train___A__変換元録音ファイル（10分程度）
           |       |_B__変換先録音ファイル（10分程度）
           |_test____test.wav（テスト用音声10秒程度）
           |       |_label.wav（比較用音声10秒程度）
           |_patch
```

学習は
`python train.py`
で、実行します。

学習はGTX1070(OCなし)環境で1時間半ほどかかります。

※大量に偏ったデータを読み込ませると学習に時間がかかるだけでなく性能が低下する場合もあります。

## 開発ポリシー

### 高速

ノートパソコンCPUでのリアルタイム推論変換実行が可能にできること
（最終目標はラズパイ）

### 低コスト

学習データの準備にかかる時間を30分以内に収まるような前処理にすること

### 少データ

規定の文章であれば10分程度の録音で足りるようにすること

## ライセンス

MIT
