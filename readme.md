# VRC(Voice Realtime Conversion)

## TL;DR

話者Aの声質を話者Bの声質にCycleGANを用いて変換するプログラムです。

1. 10分ぐらい録音して、16000Hz,16bit,モノラル,非圧縮で保存
2. 自分の声を"./dataset/train/A"に配置
3. 相手の声を"./dataset/train/B"に配置

``` bash
 python train.py
```

GTX1070なら[ ]ぐらいで終了

## インストール（環境構築）

以下のライブラリをインストールしてください。

### 変換時

- chainer
- numpy
- pyworld
- pyaudio(変換時のみ)
- matplotlib(学習時のみ)

## 学習の手順

"setting.json"ファイルで学習の設定が行なえます。
主に出力先の設定を記述します。
以下の手順で音声ファイルを用意します。

"dataset"ディレクトリを用意して、以下に"train","test","patch"を用意してください。

**16000Hz,int16,モノラル,非圧縮音声ファイル**を"dataset/train/A/"と"dataset/train/B/"に話者ごとに分けて入れてください。
なお、**同じ文章を読まなくても構いません**。ただし、データが偏った場合は正常に学習できない場合があります。

なお、学習を正常に収束させるためには5分以上の録音をお勧めします。
(台本.txtを推奨します。読みなれている場合でもおよそ5分ほどかかります。)
なお、前処理としての無音区間の削除は必要ありませんが、無音区間が長時間存在する場合の収束が保証されているわけではありません。

同条件で10秒程度のテスト用ファイル(話者A)を用意して、
"test.wav"を"dataset/test"ディレクトリ以下に保存してください。

学習は
`python train.py`
で、実行します。

学習はGTX1070(OCなし)環境で1時間半ほどかかります。

ちなみにデータは量より質です。
大量に偏ったデータを読み込ませると学習に時間がかかるだけでなく性能が低下する場合もあります。

## 開発ポリシーと達成状況

### 高速

[x] 未達成

CPUでのリアルタイム推論変換実行が可能にできること

### 安定

[x] 未達成

誰でも学習できるように安定的なネットワーク/パラメータを設定ポリシー

### 少データ

[O] 達成

規定の文章であれば10分程度の録音で足りる

## ライセンス

MIT
