# VRC(Voice Realtime Conversion)
## TL;DR
    執筆中
## 概要
 このプログラムは話者Aの声質を話者Bの声質に変換するプログラムです。
変換にCycleGANを用いています。
 

 以下のようなポリシーに沿って開発しています。

### 高速
CPUでのリアルタイム推論変換実行が可能
学習以外はCPUで動くように設計されています。 
### 安定
誰でも学習できるように安定的なパラメータを設定
### 少データ
規定の文章であれば5分程度の録音で足りる

## インストール（環境構築）
以下のライブラリをインストールしてください。

### 変換時
- chainer(>5.1.0)
- pyaudio
- pyworld(0.2.8)

### 学習時
上記に加えてテスト実施時のみ
- matplotlib

## 学習の実施方法
"setting.json"ファイルで学習の設定が行なえます。
デフォルトの状態であれば、以下の手順で音声ファイルを用意します。

"dataset"ディレクトリを用意して、以下に"source","test","train"を用意してください。

サンプリングレート16000の音声ファイル(台本.txtの読み上げを推奨します)
を"dataset/source/A/"と"dataset/source/B/"に話者ごとに分けて入れてください。

話者Aのサンプリングレート16000で10秒程度のテスト用ファイルを用意して、
"test.wav"を"dataset/test"ディレクトリ以下に保存してください。(任意)

setting.jsonを開き,use_old_datasetがfalseになっていることを確認してください。（次回からはtrueに変更することにより前処理をスキップできます。）

"VRC_Project"ディレクトリに戻り以下のコマンドを実行してください。

```
$ python train.py
```

あとは出力フォルダの音声を聞いて満足したら止めてください。
全イテレーションが終わっても満足できない場合はもう一度学習をやり直しするか、音声データを増やしてやり直してください。

学習のやり直しはtrained_modelフォルダー以下のファイルを消してください。

ちなみにデータは量より質です。
大量に偏ったデータを読み込ませると学習に時間がかかるだけでなく性能が低下する場合もあります。

## ライセンス

MIT
